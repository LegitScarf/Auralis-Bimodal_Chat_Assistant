{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "from IPython.display import Markdown,display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI key loaded!!\n",
      "Gemini key loaded!!\n"
     ]
    }
   ],
   "source": [
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "if openai_api_key:\n",
    "    print(\"OpenAI key loaded!!\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(\"Gemini key loaded!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()\n",
    "MODEL=\"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a funny and helpful assistant that answers questions in a clever and detailed way.\n",
    "If you do not know the answer of any question, please say so. Do not provide wrong answers.\n",
    "Respond in Markdown\n",
    "\"\"\"                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "    print(\"History is:\")\n",
    "    print(history)\n",
    "    print(\"And messages is:\")\n",
    "    print(messages)\n",
    "\n",
    "    stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        yield response  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'gradio.themes' from 'c:\\\\Users\\\\KIIT\\\\anaconda3\\\\envs\\\\llms\\\\Lib\\\\site-packages\\\\gradio\\\\themes\\\\__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "print(gr.themes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5.33.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://49c8fa3d1735587e3c.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://49c8fa3d1735587e3c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chatbot = gr.ChatInterface(\n",
    "    fn=chat,\n",
    "    type=\"messages\",\n",
    "    title=\"Auralis \",\n",
    "    description=\"Ask me anything! I'm here to help with a touch of humor.\",\n",
    "    theme=\"soft\",\n",
    "    chatbot=gr.Chatbot(\n",
    "        avatar_images=(\"user_avatar.png\", \"bot_avatar.png\"),\n",
    "        show_label=True,\n",
    "        type=\"messages\"\n",
    "    )\n",
    ").launch(share=True, pwa=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* Running on public URL: https://5e7c89d9166c3ebe2e.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://5e7c89d9166c3ebe2e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        yield history + [\n",
    "            {\"role\": \"user\", \"content\": message},\n",
    "            {\"role\": \"assistant\", \"content\": response}\n",
    "        ]\n",
    "\n",
    "with gr.Blocks(theme=\"soft\") as demo:\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "        <div style='display: flex; flex-direction: column; align-items: center; margin-top: 100px;'>\n",
    "            <h1 style='font-size: 2.5em; font-weight: 600;'>Auralis</h1>\n",
    "            <h2 style='font-size: 2.0em; font-weight: 500;'>What are you working on?</h2>\n",
    "        </div>\n",
    "        \"\"\",\n",
    "        elem_id=\"main-title\"\n",
    "    )\n",
    "    chatbot = gr.Chatbot(\n",
    "        avatar_images=(\"user_avatar.png\", \"bot_avatar.png\"),\n",
    "        show_label=False,\n",
    "        height=400,\n",
    "        type=\"messages\"\n",
    "    )\n",
    "    with gr.Row():\n",
    "        msg = gr.Textbox(\n",
    "            show_label=False,\n",
    "            placeholder=\"Ask anything\",\n",
    "            scale=8,\n",
    "            elem_id=\"input-box\",\n",
    "            autofocus=True,\n",
    "            container=False,\n",
    "            type=\"text\"\n",
    "        )\n",
    "        send_icon = gr.Button(value=\"\\U0001F4E7\", scale=1, elem_id=\"send-btn\")\n",
    "    msg.submit(chat, [msg, chatbot], chatbot, queue=True, scroll_to_output=True, show_progress=True, api_name=None)\n",
    "    send_icon.click(chat, [msg, chatbot], chatbot, queue=True, scroll_to_output=True, show_progress=True, api_name=None)\n",
    "\n",
    "demo.launch(share=True, pwa=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check why the diffence in:\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        yield history + [\n",
    "            {\"role\": \"user\", \"content\": message},\n",
    "            {\"role\": \"assistant\", \"content\": response}\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* Running on public URL: https://731b962f2e7d621421.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://731b962f2e7d621421.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chatbot = gr.ChatInterface(fn=chat, type=\"messages\").launch(share=True,pwa=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Generation using DALL-E-3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def artist(city):\n",
    "    image_reponse = openai.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt=f\"An image representing a vacation in {city}, showing tourist spots and everything unique about {city}.\",\n",
    "        size=\"1024x1024\",\n",
    "        n=1,\n",
    "        response_format=\"b64_json\"\n",
    "    )\n",
    "    image_base64 = image_reponse.data[0].b64_json\n",
    "    image_data = base64.b64decode(image_base64)\n",
    "    return Image.open(BytesIO(image_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = artist(\"Kolkata\")\n",
    "# display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KIIT\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\utils.py:1028: UserWarning: Expected 2 arguments for function <function chat at 0x0000028BD9FDC860>, received 1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\KIIT\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\utils.py:1032: UserWarning: Expected at least 2 arguments for function <function chat at 0x0000028BD9FDC860>, received 1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as ui:\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(height=500, type=\"messages\")\n",
    "        image_output = gr.Image(height=500)\n",
    "    with gr.Row():\n",
    "        entry = gr.Textbox(label=\"Chat with our AI Assistant:\")\n",
    "    with gr.Row():\n",
    "        clear = gr.Button(\"Clear\")\n",
    "\n",
    "    def do_entry(message, history):\n",
    "        history += [{\"role\":\"user\", \"content\":message}]\n",
    "        return \"\", history\n",
    "\n",
    "    entry.submit(do_entry, inputs=[entry, chatbot], outputs=[entry, chatbot]).then(\n",
    "        chat, inputs=chatbot, outputs=[chatbot, image_output]\n",
    "    )\n",
    "    clear.click(lambda: None, inputs=None, outputs=chatbot, queue=False)\n",
    "\n",
    "ui.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['create', 'visual', 'image', 'generate', 'picture']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are Auralis, a helpful and creative assistant.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "* Running on public URL: https://449599858bb5a8ba30.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://449599858bb5a8ba30.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "    if any(keyword in message.lower() for keyword in keywords):\n",
    "        if not message or len(message.strip()) < 5:\n",
    "            return history + [{\"role\": \"user\", \"content\": message}, {\"role\": \"assistant\", \"content\": \"Please provide a more detailed prompt to generate an image.\"}], None\n",
    "\n",
    "        image_response = openai.images.generate(\n",
    "            model=\"dall-e-3\",\n",
    "            prompt=message,\n",
    "            size=\"1024x1024\",\n",
    "            n=1,\n",
    "            response_format=\"b64_json\"\n",
    "        )\n",
    "\n",
    "        image_base64 = image_response.data[0].b64_json\n",
    "        image_data = base64.b64decode(image_base64)\n",
    "        image = Image.open(BytesIO(image_data))\n",
    "\n",
    "        return history + [{\"role\": \"user\", \"content\": message}, {\"role\": \"assistant\", \"content\": \"Here is your image!\"}], image\n",
    "\n",
    "    # Handle regular chat stream\n",
    "    response = \"\"\n",
    "    stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        yield history + [\n",
    "            {\"role\": \"user\", \"content\": message},\n",
    "            {\"role\": \"assistant\", \"content\": response}\n",
    "        ], None\n",
    "\n",
    "# === GRADIO UI ===\n",
    "with gr.Blocks(theme=\"soft\") as demo:\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "        <div style='display: flex; flex-direction: column; align-items: center; margin-top: 100px;'>\n",
    "            <h1 style='font-size: 2.5em; font-weight: 600;'>Auralis</h1>\n",
    "            <h2 style='font-size: 2.0em; font-weight: 500;'>What are you working on?</h2>\n",
    "        </div>\n",
    "        \"\"\",\n",
    "        elem_id=\"main-title\"\n",
    "    )\n",
    "\n",
    "    chatbot = gr.Chatbot(\n",
    "        avatar_images=(\"user_avatar.png\", \"bot_avatar.png\"),\n",
    "        show_label=False,\n",
    "        height=400,\n",
    "        type=\"messages\"\n",
    "    )\n",
    "    image_output = gr.Image(visible=False)\n",
    "\n",
    "    with gr.Row():\n",
    "        msg = gr.Textbox(\n",
    "            show_label=False,\n",
    "            placeholder=\"Ask anything\",\n",
    "            scale=8,\n",
    "            elem_id=\"input-box\",\n",
    "            autofocus=True,\n",
    "            container=False,\n",
    "            type=\"text\"\n",
    "        )\n",
    "        send_icon = gr.Button(value=\"\\U0001F4E7\", scale=1, elem_id=\"send-btn\")\n",
    "\n",
    "    def process_input(message, history):\n",
    "        result = chat(message, history)\n",
    "        if isinstance(result, tuple):\n",
    "            return result  # history, image (for image prompts)\n",
    "        else:\n",
    "            for updated_history, _ in result:\n",
    "                yield updated_history, None\n",
    "\n",
    "    msg.submit(process_input, [msg, chatbot], [chatbot, image_output], queue=True, scroll_to_output=True, show_progress=True)\n",
    "    send_icon.click(process_input, [msg, chatbot], [chatbot, image_output], queue=True, scroll_to_output=True, show_progress=True)\n",
    "\n",
    "demo.launch(share=True, pwa=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7871\n",
      "* Running on public URL: https://871df99184abdc02b5.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://871df99184abdc02b5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating image with prompt: Create a beautiful sunset over mountains\n",
      "API error: Error code: 500 - {'error': {'message': 'The server had an error while processing your request. Sorry about that!', 'type': 'server_error', 'param': None, 'code': None}}\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import openai\n",
    "import base64\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "MODEL = \"gpt-4o-mini\"  # or your preferred model\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")  # Make sure to set your API key\n",
    "\n",
    "# System prompt for the chatbot\n",
    "system_prompt = \"\"\"\n",
    "You are Auralis, a helpful and a funny AI assistant who gives detailed responses. You can engage in conversations on a \n",
    "wide range of topics and help users with various tasks. Be friendly and informative in your responses.\n",
    "\"\"\"\n",
    "\n",
    "# Keywords that trigger image generation\n",
    "keywords = ['create', 'visual', 'image', 'generate', 'picture', 'draw', 'make', 'design', 'art', 'illustration']\n",
    "\n",
    "def generate_image(prompt):\n",
    "    \"\"\"Generate image using DALL-E and return PIL Image object\"\"\"\n",
    "    try:\n",
    "        # Clean and validate the prompt\n",
    "        clean_prompt = prompt.strip()\n",
    "        if len(clean_prompt) > 1000:  # DALL-E has prompt limits\n",
    "            clean_prompt = clean_prompt[:1000]\n",
    "        \n",
    "        # Add some delay to avoid rate limiting\n",
    "        import time\n",
    "        time.sleep(1)\n",
    "        \n",
    "        print(f\"Generating image with prompt: {clean_prompt}\")  # Debug logging\n",
    "        \n",
    "        image_response = openai.images.generate(\n",
    "            model=\"dall-e-3\",\n",
    "            prompt=clean_prompt,\n",
    "            size=\"1024x1024\",\n",
    "            n=1,\n",
    "            response_format=\"b64_json\",\n",
    "            quality=\"standard\"  # Use standard quality to reduce costs and server load\n",
    "        )\n",
    "        \n",
    "        # Process the image\n",
    "        image_base64 = image_response.data[0].b64_json\n",
    "        image_data = base64.b64decode(image_base64)\n",
    "        \n",
    "        # Convert to PIL Image\n",
    "        image = Image.open(BytesIO(image_data))\n",
    "        print(\"Image generated successfully!\")  # Debug logging\n",
    "        return image, None\n",
    "        \n",
    "    except openai.RateLimitError as e:\n",
    "        error_msg = \"Rate limit exceeded. Please wait a moment before generating another image.\"\n",
    "        print(f\"Rate limit error: {e}\")\n",
    "        return None, error_msg\n",
    "    except openai.APIError as e:\n",
    "        error_msg = f\"OpenAI API error: {e.message if hasattr(e, 'message') else str(e)}\"\n",
    "        print(f\"API error: {e}\")\n",
    "        return None, error_msg\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Unexpected error generating image: {str(e)}\"\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        return None, error_msg\n",
    "\n",
    "def generate_text_response_streaming(message, history):\n",
    "    \"\"\"Generate streaming text response using OpenAI API\"\"\"\n",
    "    try:\n",
    "        messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "        \n",
    "        stream = openai.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=messages,\n",
    "            stream=True\n",
    "        )\n",
    "        \n",
    "        # Yield chunks of the response as they come in\n",
    "        for chunk in stream:\n",
    "            if chunk.choices[0].delta.content is not None:\n",
    "                yield chunk.choices[0].delta.content\n",
    "                \n",
    "    except Exception as e:\n",
    "        yield f\"Sorry, I encountered an error: {str(e)}\"\n",
    "\n",
    "def chat_interface_streaming(message, history):\n",
    "    \"\"\"Main chat interface function with streaming support\"\"\"\n",
    "    if not message or not message.strip():\n",
    "        yield history, None\n",
    "        return\n",
    "    \n",
    "    # Check if we should generate an image\n",
    "    should_generate_image = any(keyword in message.lower() for keyword in keywords)\n",
    "    \n",
    "    if should_generate_image:\n",
    "        # More robust validation for image generation\n",
    "        clean_message = message.strip()\n",
    "        if len(clean_message) < 10:\n",
    "            error_msg = \"Please provide a more detailed description (at least 10 characters) to generate a high-quality image.\"\n",
    "            new_history = history + [{\"role\": \"user\", \"content\": message}, {\"role\": \"assistant\", \"content\": error_msg}]\n",
    "            yield new_history, None\n",
    "            return\n",
    "        \n",
    "        # Check for potentially problematic content\n",
    "        forbidden_words = ['nsfw', 'nude', 'explicit', 'violence', 'blood', 'gore']\n",
    "        if any(word in clean_message.lower() for word in forbidden_words):\n",
    "            error_msg = \"I can't generate images with that content. Please try a different, more appropriate prompt.\"\n",
    "            new_history = history + [{\"role\": \"user\", \"content\": message}, {\"role\": \"assistant\", \"content\": error_msg}]\n",
    "            yield new_history, None\n",
    "            return\n",
    "        \n",
    "        # Show generating message\n",
    "        generating_msg = f\"🎨 Generating image for: '{clean_message}'\\nThis may take a few moments...\"\n",
    "        temp_history = history + [{\"role\": \"user\", \"content\": message}, {\"role\": \"assistant\", \"content\": generating_msg}]\n",
    "        yield temp_history, None\n",
    "        \n",
    "        # Generate image\n",
    "        image, error = generate_image(clean_message)\n",
    "        \n",
    "        if error:\n",
    "            # Return error message with suggestions\n",
    "            if \"rate limit\" in error.lower():\n",
    "                error_msg = f\"{error}\\n\\n💡 Tip: Try waiting 30-60 seconds before generating another image.\"\n",
    "            elif \"server\" in error.lower():\n",
    "                error_msg = f\"{error}\\n\\n💡 Tip: OpenAI servers might be busy. Try again in a few minutes, or try a simpler prompt.\"\n",
    "            else:\n",
    "                error_msg = f\"{error}\\n\\n💡 Tip: Try rephrasing your prompt or making it more specific.\"\n",
    "            \n",
    "            new_history = history + [{\"role\": \"user\", \"content\": message}, {\"role\": \"assistant\", \"content\": error_msg}]\n",
    "            yield new_history, None\n",
    "        else:\n",
    "            # Return success message with image\n",
    "            response_text = f\"✨ Here's your generated image: '{clean_message}'\"\n",
    "            new_history = history + [{\"role\": \"user\", \"content\": message}, {\"role\": \"assistant\", \"content\": response_text}]\n",
    "            yield new_history, image\n",
    "    \n",
    "    else:\n",
    "        # Generate streaming text response\n",
    "        new_history = history + [{\"role\": \"user\", \"content\": message}, {\"role\": \"assistant\", \"content\": \"\"}]\n",
    "        \n",
    "        assistant_message = \"\"\n",
    "        for text_chunk in generate_text_response_streaming(message, history):\n",
    "            assistant_message += text_chunk\n",
    "            # Update the last message in history with the accumulated response\n",
    "            new_history[-1][\"content\"] = assistant_message\n",
    "            yield new_history, None\n",
    "\n",
    "def submit_message(message, history):\n",
    "    \"\"\"Handle message submission with streaming support\"\"\"\n",
    "    if not message.strip():\n",
    "        return history, None, \"\"\n",
    "    \n",
    "    # Use the streaming chat interface\n",
    "    for new_history, image in chat_interface_streaming(message, history):\n",
    "        yield new_history, image, \"\"  # Clear input field\n",
    "\n",
    "def clear_chat():\n",
    "    \"\"\"Clear the chat history\"\"\"\n",
    "    return [], None\n",
    "\n",
    "# Custom CSS for better styling\n",
    "css = \"\"\"\n",
    "#main-title {\n",
    "    text-align: center;\n",
    "    margin-bottom: 30px;\n",
    "}\n",
    "\n",
    "#input-box {\n",
    "    border-radius: 25px !important;\n",
    "    border: 2px solid #e0e0e0 !important;\n",
    "    padding: 12px 20px !important;\n",
    "    font-size: 16px !important;\n",
    "}\n",
    "\n",
    "#send-btn {\n",
    "    border-radius: 50% !important;\n",
    "    width: 50px !important;\n",
    "    height: 50px !important;\n",
    "    min-width: 50px !important;\n",
    "    background-color: white !important;\n",
    "    border: 2px solid #e0e0e0 !important;\n",
    "    color: #333 !important;\n",
    "    font-size: 18px !important;\n",
    "    margin-left: 10px !important;\n",
    "    display: flex !important;\n",
    "    align-items: center !important;\n",
    "    justify-content: center !important;\n",
    "}\n",
    "\n",
    "#send-btn:hover {\n",
    "    transform: scale(1.05) !important;\n",
    "    box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1) !important;\n",
    "    border-color: #ccc !important;\n",
    "}\n",
    "\n",
    ".chatbot {\n",
    "    border-radius: 15px !important;\n",
    "    border: 1px solid #e0e0e0 !important;\n",
    "}\n",
    "\n",
    "#clear-btn {\n",
    "    background-color: #ff6b6b !important;\n",
    "    color: white !important;\n",
    "    border: none !important;\n",
    "    border-radius: 20px !important;\n",
    "    padding: 8px 16px !important;\n",
    "    margin-bottom: 10px !important;\n",
    "}\n",
    "\n",
    "#clear-btn:hover {\n",
    "    background-color: #ff5252 !important;\n",
    "    transform: scale(1.02) !important;\n",
    "}\n",
    "\n",
    ".image-container {\n",
    "    border-radius: 15px !important;\n",
    "    border: 1px solid #e0e0e0 !important;\n",
    "    margin-top: 10px !important;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Create the Gradio interface\n",
    "with gr.Blocks(theme=gr.themes.Soft(), css=css, title=\"Auralis - AI Assistant\") as demo:\n",
    "    # Header\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "        <div style='display: flex; flex-direction: column; align-items: center; margin-top: 100px;'>\n",
    "            <h1 style='font-size: 4.0em; font-weight: 600;'>Auralis</h1>\n",
    "            <h2 style='font-size: 2.0em; font-weight: 500;'>What are you working on?</h2>\n",
    "        </div>\n",
    "        \"\"\",\n",
    "        elem_id=\"main-title\"\n",
    "    )\n",
    "    \n",
    "    # Clear button\n",
    "    with gr.Row():\n",
    "        clear_button = gr.Button(\"🗑️ Clear Chat\", elem_id=\"clear-btn\", size=\"sm\")\n",
    "    \n",
    "    # Chat interface\n",
    "    chatbot = gr.Chatbot(\n",
    "        show_label=False,\n",
    "        height=500,\n",
    "        type=\"messages\",\n",
    "        avatar_images=(\"user_avatar.png\", \"bot_avatar.png\"),\n",
    "        elem_classes=[\"chatbot\"]\n",
    "    )\n",
    "    \n",
    "    # Image output (will show generated images)\n",
    "    image_output = gr.Image(\n",
    "        label=\"Generated Image\", \n",
    "        visible=True, \n",
    "        elem_classes=[\"image-container\"],\n",
    "        height=400  # Increased height for better visibility\n",
    "    )\n",
    "    \n",
    "    # Input section\n",
    "    with gr.Row():\n",
    "        msg = gr.Textbox(\n",
    "            show_label=False,\n",
    "            placeholder=\"Type your message here... (use words like 'create', 'generate', 'draw' for images)\",\n",
    "            scale=9,\n",
    "            elem_id=\"input-box\",\n",
    "            autofocus=True,\n",
    "            container=False,\n",
    "            lines=1,\n",
    "            max_lines=3\n",
    "        )\n",
    "        send_btn = gr.Button(\"↑\", scale=1, elem_id=\"send-btn\")\n",
    "    \n",
    "    # Event handlers\n",
    "    msg.submit(\n",
    "        submit_message,\n",
    "        inputs=[msg, chatbot],\n",
    "        outputs=[chatbot, image_output, msg],\n",
    "        queue=True\n",
    "    )\n",
    "    \n",
    "    send_btn.click(\n",
    "        submit_message,\n",
    "        inputs=[msg, chatbot],\n",
    "        outputs=[chatbot, image_output, msg],\n",
    "        queue=True\n",
    "    )\n",
    "    \n",
    "    # Clear chat functionality\n",
    "    clear_button.click(\n",
    "        clear_chat,\n",
    "        outputs=[chatbot, image_output],\n",
    "        queue=False\n",
    "    )\n",
    "    \n",
    "    # Example prompts\n",
    "    gr.Examples(\n",
    "        examples=[\n",
    "            [\"What is artificial intelligence?\"],\n",
    "            [\"Create a beautiful sunset over mountains\"],\n",
    "            [\"Explain quantum computing in simple terms\"],\n",
    "            [\"Generate an image of a futuristic city\"],\n",
    "            [\"What are the benefits of renewable energy?\"],\n",
    "            [\"Draw a cute robot helping humans\"]\n",
    "        ],\n",
    "        inputs=msg,\n",
    "        label=\"Try these examples:\"\n",
    "    )\n",
    "\n",
    "# Launch the app\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(share=True, pwa=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def talker(message):\n",
    "    response = openai.audio.speech.create(\n",
    "      model=\"tts-1\",\n",
    "      voice=\"onyx\",    # Also, try replacing onyx with alloy\n",
    "      input=message\n",
    "    )\n",
    "    \n",
    "    audio_stream = BytesIO(response.content)\n",
    "    audio = AudioSegment.from_file(audio_stream, format=\"mp3\")\n",
    "    play(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KIIT\\anaconda3\\envs\\llms\\Lib\\site-packages\\pydub\\utils.py:198: RuntimeWarning: Couldn't find ffprobe or avprobe - defaulting to ffprobe, but may not work\n",
      "  warn(\"Couldn't find ffprobe or avprobe - defaulting to ffprobe, but may not work\", RuntimeWarning)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtalker\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWell, hi there\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mtalker\u001b[39m\u001b[34m(message)\u001b[39m\n\u001b[32m      2\u001b[39m response = openai.audio.speech.create(\n\u001b[32m      3\u001b[39m   model=\u001b[33m\"\u001b[39m\u001b[33mtts-1\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      4\u001b[39m   voice=\u001b[33m\"\u001b[39m\u001b[33monyx\u001b[39m\u001b[33m\"\u001b[39m,    \u001b[38;5;66;03m# Also, try replacing onyx with alloy\u001b[39;00m\n\u001b[32m      5\u001b[39m   \u001b[38;5;28minput\u001b[39m=message\n\u001b[32m      6\u001b[39m )\n\u001b[32m      8\u001b[39m audio_stream = BytesIO(response.content)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m audio = \u001b[43mAudioSegment\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmp3\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m play(audio)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KIIT\\anaconda3\\envs\\llms\\Lib\\site-packages\\pydub\\audio_segment.py:728\u001b[39m, in \u001b[36mAudioSegment.from_file\u001b[39m\u001b[34m(cls, file, format, codec, parameters, start_second, duration, **kwargs)\u001b[39m\n\u001b[32m    726\u001b[39m     info = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m728\u001b[39m     info = \u001b[43mmediainfo_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43morig_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread_ahead_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread_ahead_limit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m info:\n\u001b[32m    730\u001b[39m     audio_streams = [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m info[\u001b[33m'\u001b[39m\u001b[33mstreams\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    731\u001b[39m                      \u001b[38;5;28;01mif\u001b[39;00m x[\u001b[33m'\u001b[39m\u001b[33mcodec_type\u001b[39m\u001b[33m'\u001b[39m] == \u001b[33m'\u001b[39m\u001b[33maudio\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KIIT\\anaconda3\\envs\\llms\\Lib\\site-packages\\pydub\\utils.py:274\u001b[39m, in \u001b[36mmediainfo_json\u001b[39m\u001b[34m(filepath, read_ahead_limit)\u001b[39m\n\u001b[32m    271\u001b[39m         file.close()\n\u001b[32m    273\u001b[39m command = [prober, \u001b[33m'\u001b[39m\u001b[33m-of\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mjson\u001b[39m\u001b[33m'\u001b[39m] + command_args\n\u001b[32m--> \u001b[39m\u001b[32m274\u001b[39m res = \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstdin_parameter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstderr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPIPE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    275\u001b[39m output, stderr = res.communicate(\u001b[38;5;28minput\u001b[39m=stdin_data)\n\u001b[32m    276\u001b[39m output = output.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KIIT\\anaconda3\\envs\\llms\\Lib\\subprocess.py:1026\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[39m\n\u001b[32m   1022\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.text_mode:\n\u001b[32m   1023\u001b[39m             \u001b[38;5;28mself\u001b[39m.stderr = io.TextIOWrapper(\u001b[38;5;28mself\u001b[39m.stderr,\n\u001b[32m   1024\u001b[39m                     encoding=encoding, errors=errors)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1028\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1033\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1036\u001b[39m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[32m   1037\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m.stdin, \u001b[38;5;28mself\u001b[39m.stdout, \u001b[38;5;28mself\u001b[39m.stderr)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KIIT\\anaconda3\\envs\\llms\\Lib\\subprocess.py:1538\u001b[39m, in \u001b[36mPopen._execute_child\u001b[39m\u001b[34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[39m\n\u001b[32m   1536\u001b[39m \u001b[38;5;66;03m# Start the process\u001b[39;00m\n\u001b[32m   1537\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1538\u001b[39m     hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n\u001b[32m   1539\u001b[39m                              \u001b[38;5;66;03m# no special security\u001b[39;00m\n\u001b[32m   1540\u001b[39m                              \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1541\u001b[39m                              \u001b[38;5;28mint\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m close_fds),\n\u001b[32m   1542\u001b[39m                              creationflags,\n\u001b[32m   1543\u001b[39m                              env,\n\u001b[32m   1544\u001b[39m                              cwd,\n\u001b[32m   1545\u001b[39m                              startupinfo)\n\u001b[32m   1546\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1547\u001b[39m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[32m   1548\u001b[39m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1551\u001b[39m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[32m   1552\u001b[39m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n\u001b[32m   1553\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_pipe_fds(p2cread, p2cwrite,\n\u001b[32m   1554\u001b[39m                          c2pread, c2pwrite,\n\u001b[32m   1555\u001b[39m                          errread, errwrite)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 2] The system cannot find the file specified"
     ]
    }
   ],
   "source": [
    "talker(\"Well, hi there\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt=\"\"\"\n",
    "Give me a detailed analysis of what is google is what it does!!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, clear_output\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Alright, buckle up, buttercup, because we're about to dive deep into the Google-verse!\n",
       "\n",
       "**What is Google? A Multi-Faceted Entity**\n",
       "\n",
       "On the surface, Google is a search engine. But that's like saying the Mona Lisa is just a painting. Google has evolved into a sprawling, tentacled, digital octopus with its suckers in pretty much everything. Here's a breakdown:\n",
       "\n",
       "*   **The OG: The Search Engine:** This is the granddaddy of them all. You type in a query, and Google's algorithms (a super-secret sauce of mathematical wizardry) crawl the entire internet to give you a ranked list of relevant websites. It's how most people start their online journey.\n",
       "\n",
       "*   **A Software Juggernaut:** Google's not just about search. They have a whole suite of software products:\n",
       "\n",
       "    *   **Android:** The most popular mobile operating system in the world. If you have a non-Apple smartphone, chances are it's running Android.\n",
       "    *   **Chrome:** A web browser that's practically synonymous with \"internet.\"\n",
       "    *   **Gmail:** Email service with a huge storage capacity.\n",
       "    *   **Google Docs, Sheets, Slides:** Their answer to Microsoft Office, but free and cloud-based.\n",
       "    *   **Google Maps:** A mapping service which most people rely on to navigate these days.\n",
       "    *   **YouTube:** The world's biggest video-sharing platform.\n",
       "    *   **Google Drive:** Cloud storage, so you can keep your files safe and access them from anywhere.\n",
       "    *   **Google Photos:** Photo storage and organization.\n",
       "    *   **Google Meet:** Video conferencing, similar to Zoom.\n",
       "    *   **Google Calendar:** Scheduling and reminders.\n",
       "    *   **Google Translate:** The translator.\n",
       "    *   **Google News:** A news aggregator.\n",
       "\n",
       "*   **Hardware Player:** Google makes stuff you can touch.\n",
       "\n",
       "    *   **Pixel Phones:** Their own line of smartphones.\n",
       "    *   **Nest Products:** Smart home devices like thermostats, security cameras, and doorbells.\n",
       "    *   **Chromecast:** A device that lets you stream content from your phone or computer to your TV.\n",
       "    *   **Google Wifi:** Mesh wifi systems for better home internet coverage.\n",
       "\n",
       "*   **AI and Machine Learning Pioneer:** Google is heavily invested in artificial intelligence and machine learning:\n",
       "\n",
       "    *   **Google AI:** A research division dedicated to pushing the boundaries of AI.\n",
       "    *   **TensorFlow:** An open-source machine learning framework used by researchers and developers worldwide.\n",
       "    *   **Google Assistant:** A virtual assistant that can answer questions, set alarms, control smart home devices, and more.\n",
       "    *   **Bard:** Google's answer to Chat GPT.\n",
       "\n",
       "*   **A Data Colossus:** Google collects a *lot* of data. Every search you make, every website you visit (if they have Google Analytics installed), every video you watch on YouTube – it's all data that Google can use to personalize ads, improve its services, and build better AI models. This is both incredibly useful and a little bit creepy, depending on your perspective.\n",
       "\n",
       "**What Does Google Do? The Core Functions**\n",
       "\n",
       "So, what does Google *do* with all this power and reach?\n",
       "\n",
       "*   **Organizes Information:** Google's primary mission is to \"organize the world's information and make it universally accessible and useful.\" The search engine is the flagship manifestation of this mission, but it extends to Google Scholar (for academic research), Google Books (for digitizing books), and other projects.\n",
       "\n",
       "*   **Connects People to Information:** It's not just about organizing data; it's about getting the right information to the right people at the right time. Google's algorithms are constantly being refined to deliver more relevant and personalized search results.\n",
       "\n",
       "*   **Monetizes Through Advertising:** The vast majority of Google's revenue comes from advertising. They sell ad space on their search results pages, on YouTube, on websites that use Google AdSense, and within their mobile apps. The more targeted the ads, the more valuable they are.\n",
       "\n",
       "*   **Innovates:** Google is constantly experimenting with new technologies and products. Some of these efforts become wildly successful (like Android), while others fade away (remember Google Glass?). They're willing to take risks and invest in the future.\n",
       "\n",
       "*   **Shapes the Internet:** Google has a massive influence on how the internet works. Their search algorithms can make or break websites. Their open-source projects like TensorFlow and Kubernetes shape the development landscape. And their decisions about privacy and security have a ripple effect across the entire web.\n",
       "\n",
       "**In a Nutshell**\n",
       "\n",
       "Google is more than just a search engine; it's a technological powerhouse that touches nearly every aspect of our digital lives. It's a company that organizes information, connects people, monetizes data, innovates relentlessly, and shapes the internet as we know it.\n",
       "\n",
       "**Disclaimer:** This is a simplified explanation, of course. The inner workings of Google are complex and constantly evolving. But hopefully, this gives you a comprehensive overview of what Google is and what it does.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemini = google.generativeai.GenerativeModel(\n",
    "    model_name='gemini-2.0-flash',\n",
    "    system_instruction=system_prompt\n",
    ")\n",
    "response = gemini.generate_content(user_prompt, stream=True)\n",
    "\n",
    "content = ''\n",
    "for chunk in response:\n",
    "    content += chunk.text\n",
    "    clear_output(wait=True)\n",
    "    display(Markdown(content))\n",
    "    time.sleep(0.05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
